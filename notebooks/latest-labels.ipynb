{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993fa31a-064a-4e40-a964-100b4a99dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a94a2e8-f666-4570-9f27-e8d2fc79b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATA\n",
    "cwd = os.getcwd()\n",
    "release = '20240312'\n",
    "\n",
    "labels = pd.read_csv(f'../releases/v2.0.0/{release}/adverse_reactions_active_labels.csv.gz', compression='gzip')\n",
    "meta_data = pd.read_csv(f'../releases/v2.0.0/{release}/dm_spl_zip_files_meta_data.csv.gz', compression='gzip')\n",
    "ingredients = pd.read_csv(f'../releases/v2.0.0/{release}/ingredients.csv.gz', compression='gzip')\n",
    "rx_map = pd.read_csv(f'../releases/v2.0.0/{release}/rxnorm_mappings.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f361864-ac12-4a83-9faf-1c53cca83ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique set ids:  32839\n",
      "Number of unique ingredients for all labels: 2795\n",
      "Labels with one ingredient:  29057\n",
      "Number of unique ingredients for one-ingredient labels:  1468\n"
     ]
    }
   ],
   "source": [
    "latest_labels = labels.merge(meta_data, left_on = 'set_id', right_on = 'SETID')\n",
    "latest_ingredients = ingredients.merge(meta_data, left_on = 'set_id', right_on = 'SETID')\n",
    "one_ingredient = labels[labels['num_ingredients'] == 1]\n",
    "one_labels = one_ingredient.set_id.to_list()\n",
    "latest_ingredients = latest_ingredients[latest_ingredients['set_id'].isin(one_labels)]\n",
    "\n",
    "print('Number of unique set ids: ', len(latest_labels.set_id.unique()))\n",
    "print(\"Number of unique ingredients for all labels:\", len(ingredients.ingredient_rx_cui.unique()))\n",
    "print('Labels with one ingredient: ', len(latest_ingredients.set_id.unique()))\n",
    "print('Number of unique ingredients for one-ingredient labels: ', len(latest_ingredients.ingredient_rx_cui.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2712a96c-97bb-46ef-815b-bc209658fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_labels['UPLOAD_DATE'] = pd.to_datetime(latest_labels['UPLOAD_DATE'])\n",
    "latest_ingredients['UPLOAD_DATE'] = pd.to_datetime(latest_ingredients['UPLOAD_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702f36ff-da23-449c-9637-7ebbd646ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_filter(df, groupby_col):\n",
    "    result_df = df.groupby(groupby_col).apply(lambda x: x[x['UPLOAD_DATE'] == x['UPLOAD_DATE'].max()])\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca049c4-2550-4c50-b27e-892876fddc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_df = latest_filter(latest_ingredients, 'ingredient_rx_cui')\n",
    "labels_df = latest_filter(latest_labels, 'set_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7336e9-f4e6-4cc1-b475-5164eb283cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_ids = set(list(ingredients_df.SETID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadc9fcc-a26e-4c63-99e2-9a45b622aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Filter rows based on 'set_id' and drop duplicates\n",
    "ingredients_df = ingredients_df[ingredients_df['set_id'].isin(ingredient_ids)]\n",
    "ingredients_df = ingredients_df.drop_duplicates(subset=['set_id', 'TITLE'])\n",
    "\n",
    "# Group by ingredient get the latest spl_version, sample if there are multiple labels with the same upload date and spl version\n",
    "ingredients_df = ingredients_df.groupby('ingredient_rx_cui').apply(lambda x: x[x['SPL_VERSION'] == x['SPL_VERSION'].max()].sample(1)).reset_index(drop=True)\n",
    "\n",
    "# ingredients_df.ingredient_rx_cui.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b596b5d4-4180-4c7b-966c-8967fc736e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = labels_df.groupby(['set_id', 'spl_version']).agg({\n",
    "    'pt_meddra_term': list,\n",
    "    'pt_meddra_id': list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c471e7-2c30-45a0-907b-1be8c7bc333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_spl_dict(df, spl_col):\n",
    "    grouped = df.groupby('set_id')[spl_col].apply(list)\n",
    "    dict = grouped.to_dict()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6181ceef-2024-4e14-9d91-550cf7bb2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_ids = set_spl_dict(ingredients_df, 'SPL_VERSION')\n",
    "label_ids = set_spl_dict(labels_df, 'spl_version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f8cc682-bf60-4145-949a-e4cfc2ad6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_json_files(directory, filtered_set_ids):\n",
    "    selected_files = []\n",
    "\n",
    "    # Iterate through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Open and read the JSON file\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                    # Check if both set_id and label_id are in the filtered lists\n",
    "                    if 'set_id' in data and 'spl_version' in data:\n",
    "                        if data['set_id'] in filtered_set_ids:\n",
    "                            if int(data['spl_version']) in filtered_set_ids[data['set_id']]:\n",
    "                                selected_files.append(filename)\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON in file: {filename}\")\n",
    "\n",
    "    return selected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64735c13-92c6-408c-9117-96e6a4cc8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_labels(ids):\n",
    "    lst = []\n",
    "    for num in range(5):\n",
    "        directory = '../../onsides-v4/data/spl/rx/dm_spl_release_human_rx_part' + str(num + 1) + '/prescription'\n",
    "        lst.append(select_json_files(directory, ids))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef86677-7bdc-407b-aeb3-8bee33464194",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ingredients = select_labels(ingredient_ids)\n",
    "selected_labels = select_labels(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe3ba09-387c-4c4b-a5c8-cbad3e08bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(lst, label_type):\n",
    "    count = [item for row in lst for item in row]\n",
    "    print(f'number of {label_type} labels:', len(count))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92334a83-921e-46d9-9cab-4a54da4938f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ingredient labels: 1468\n",
      "number of latest labels: 32839\n"
     ]
    }
   ],
   "source": [
    "selected_ingredients = flatten_list(selected_ingredients, \"ingredient\")\n",
    "selected_labels = flatten_list(selected_labels, \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbcd8759-441e-49a9-9e1b-a1ab7f075f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_jsons(directory, ids_list):\n",
    "    destination_directory = f'../../onsides-v4/data/{directory}/'\n",
    "    \n",
    "    # Clear the destination directory first\n",
    "    if os.path.exists(destination_directory):\n",
    "        # Remove the entire directory and its contents\n",
    "        shutil.rmtree(destination_directory)\n",
    "    \n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "    \n",
    "    # Now proceed to copy or move files\n",
    "    for num in tqdm(range(5)):\n",
    "        directory = '../../onsides-v4/data/spl/rx/dm_spl_release_human_rx_part' + str(num + 1) + '/prescription'\n",
    "        \n",
    "        for file in ids_list:\n",
    "            # Ensure 'file' is a string and not something else\n",
    "            if not isinstance(file, (str, bytes, os.PathLike)):\n",
    "                print(f\"Skipping invalid file: {file}\")\n",
    "                continue\n",
    "    \n",
    "            file_path = os.path.join(directory, file)\n",
    "    \n",
    "            if not os.path.exists(file_path):\n",
    "                # print(f\"File does not exist: {file_path}\")\n",
    "                continue\n",
    "    \n",
    "            # Copy or move the file\n",
    "            shutil.copy(file_path, destination_directory)\n",
    "            # print(f\"Copied: {file_path} to {destination_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "486b29e8-99ad-4612-86cf-4d2d34cb57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  7.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:15<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "allocate_jsons(\"latest_labels_ingredients\", selected_ingredients)\n",
    "allocate_jsons(\"latest_labels\", selected_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83359ff-f9ea-4766-84c9-c8759caad4ba",
   "metadata": {},
   "source": [
    "### COLLECT LATEST TRAIN_XML AND GOLD_XML FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27da69ff-26d1-40bc-876b-94636f3fbe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tac_filenames(directory_path):\n",
    "    lst = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        prefix = filename.split('_')[0]\n",
    "        lst.append(prefix)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9433cfc6-6a41-4b64-8707-80602f3ca5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles = tac_filenames('../data/train_xml')\n",
    "gold_titles = tac_filenames('../data/gold_xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090a78dc-a42c-43e9-a61f-ddf948a0ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tac_df(label_list):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for label_name in label_list:\n",
    "        label_filter = meta_data['TITLE'].str.contains(label_name, na=False)\n",
    "        df = pd.concat([df, meta_data[label_filter]], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe765995-12fb-457c-86df-ab7ad619ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tac_df(train_titles)\n",
    "gold_df = tac_df(gold_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5297ee12-bb77-429b-be00-13df1c3e9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_title(title, title_list):\n",
    "    # Iterate through the list and return the title if it's in the title string\n",
    "    for list_title in title_list:\n",
    "        if list_title in title:\n",
    "            return list_title\n",
    "    return None  # Return None or some default value if no match is found\n",
    "\n",
    "# Apply the custom function to the 'TITLE' column\n",
    "train_df['xml_title'] = train_df['TITLE'].apply(lambda x: match_title(x, train_titles))\n",
    "gold_df['xml_title'] = gold_df['TITLE'].apply(lambda x: match_title(x, gold_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "318310ea-b4c5-45d8-9397-5e681636cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_filter(df, groupby_col):\n",
    "    result_df = df.groupby(groupby_col).apply(lambda x: x[x['UPLOAD_DATE'] == x['UPLOAD_DATE'].max()])\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd5980d-9d8f-42b8-bea9-45865996bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = latest_filter(train_df, 'xml_title')\n",
    "gold_df = latest_filter(gold_df, 'xml_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5be5d5c2-e837-4d34-a874-0bb67d75a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'xml_title' and get the max 'UPLOAD_DATE' for each group\n",
    "latest_train = train_df.groupby('xml_title')['SPL_VERSION'].max().reset_index()\n",
    "latest_gold = gold_df.groupby('xml_title')['SPL_VERSION'].max().reset_index()\n",
    "\n",
    "\n",
    "# Merge this back with the original train_df to get the full rows\n",
    "train_df = pd.merge(train_df, latest_train, on=['xml_title', 'SPL_VERSION'])\n",
    "gold_df = pd.merge(gold_df, latest_gold, on=['xml_title', 'SPL_VERSION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "494294a4-d2c8-47ea-9041-c4ae03df7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "print(train_df['xml_title'].nunique())\n",
    "print(gold_df['xml_title'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28eb8fdb-44d2-4ae9-a621-2d9d98cc2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = gold_df.drop_duplicates(subset = ['xml_title', 'SPL_VERSION'])\n",
    "train_df = train_df.drop_duplicates(subset = ['xml_title', 'SPL_VERSION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec0e50d1-5ee3-45b7-abbc-39112ad37edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = {}\n",
    "for setid in train_df.SETID.unique():\n",
    "    train_ids[setid] = train_df[train_df.SETID == setid].SPL_VERSION.tolist()\n",
    "\n",
    "gold_ids = {}\n",
    "for setid in gold_df.SETID.unique():\n",
    "    gold_ids[setid] = gold_df[gold_df.SETID == setid].SPL_VERSION.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "400232c7-eb40-4db0-ad38-c8c689b4618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_select = []\n",
    "for num in range(5):\n",
    "    directory = '../../onsides-v4/data/spl/rx/dm_spl_release_human_rx_part' + str(num + 1) + '/prescription'\n",
    "    train_select.append(select_json_files(directory, train_ids))\n",
    "    \n",
    "# print(\"Selected JSON Files:\", train_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13d411dd-341c-4f7f-b419-c60f57830b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_select = [item for row in train_select for item in row]\n",
    "len(train_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fe0a303-0b9a-4fd5-b0c6-46582b8d4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_select = []\n",
    "for num in range(5):\n",
    "    directory = '../../onsides-v4/data/spl/rx/dm_spl_release_human_rx_part' + str(num + 1) + '/prescription'\n",
    "    gold_select.append(select_json_files(directory, gold_ids))\n",
    "    \n",
    "# print(\"Selected JSON Files:\", gold_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0db54ffa-984c-4706-8cf0-eb7d7babb1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_select = [item for row in gold_select for item in row]\n",
    "len(gold_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36e28369-5bff-4edc-a5ca-a44ce167701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SETID</th>\n",
       "      <th>ZIP_FILE_NAME</th>\n",
       "      <th>UPLOAD_DATE</th>\n",
       "      <th>SPL_VERSION</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>xml_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3904f8dd-1aef-3490-e48f-bd55f32ed67f</td>\n",
       "      <td>20230627_3904f8dd-1aef-3490-e48f-bd55f32ed67f.zip</td>\n",
       "      <td>06/27/2023</td>\n",
       "      <td>34</td>\n",
       "      <td>ADCETRIS (BRENTUXIMAB VEDOTIN) INJECTION, POWD...</td>\n",
       "      <td>ADCETRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c89d3ecc-4f4c-4566-8808-79152344194d</td>\n",
       "      <td>20240112_c89d3ecc-4f4c-4566-8808-79152344194d.zip</td>\n",
       "      <td>01/12/2024</td>\n",
       "      <td>9</td>\n",
       "      <td>ADREVIEW (IOBENGUANE I-123) INJECTION [MEDI-PH...</td>\n",
       "      <td>ADREVIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2150f73a-179b-4afc-b8ce-67c85cc72f04</td>\n",
       "      <td>20230802_2150f73a-179b-4afc-b8ce-67c85cc72f04.zip</td>\n",
       "      <td>08/02/2023</td>\n",
       "      <td>60</td>\n",
       "      <td>AFINITOR (EVEROLIMUS) TABLET AFINITOR DISPERZ ...</td>\n",
       "      <td>AFINITOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550eb76a-e4a6-4fa1-ad65-c0fd8b0ce783</td>\n",
       "      <td>20230124_550eb76a-e4a6-4fa1-ad65-c0fd8b0ce783.zip</td>\n",
       "      <td>01/24/2023</td>\n",
       "      <td>17</td>\n",
       "      <td>AMPYRA (DALFAMPRIDINE) TABLET, FILM COATED, EX...</td>\n",
       "      <td>AMPYRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb5a5043-0f51-11df-8a39-0800200c9a66</td>\n",
       "      <td>20231114_bb5a5043-0f51-11df-8a39-0800200c9a66.zip</td>\n",
       "      <td>11/14/2023</td>\n",
       "      <td>20</td>\n",
       "      <td>AMYVID (FLORBETAPIR F 18) INJECTION, SOLUTION ...</td>\n",
       "      <td>AMYVID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  SETID  \\\n",
       "0  3904f8dd-1aef-3490-e48f-bd55f32ed67f   \n",
       "1  c89d3ecc-4f4c-4566-8808-79152344194d   \n",
       "2  2150f73a-179b-4afc-b8ce-67c85cc72f04   \n",
       "3  550eb76a-e4a6-4fa1-ad65-c0fd8b0ce783   \n",
       "4  bb5a5043-0f51-11df-8a39-0800200c9a66   \n",
       "\n",
       "                                       ZIP_FILE_NAME UPLOAD_DATE  SPL_VERSION  \\\n",
       "0  20230627_3904f8dd-1aef-3490-e48f-bd55f32ed67f.zip  06/27/2023           34   \n",
       "1  20240112_c89d3ecc-4f4c-4566-8808-79152344194d.zip  01/12/2024            9   \n",
       "2  20230802_2150f73a-179b-4afc-b8ce-67c85cc72f04.zip  08/02/2023           60   \n",
       "3  20230124_550eb76a-e4a6-4fa1-ad65-c0fd8b0ce783.zip  01/24/2023           17   \n",
       "4  20231114_bb5a5043-0f51-11df-8a39-0800200c9a66.zip  11/14/2023           20   \n",
       "\n",
       "                                               TITLE xml_title  \n",
       "0  ADCETRIS (BRENTUXIMAB VEDOTIN) INJECTION, POWD...  ADCETRIS  \n",
       "1  ADREVIEW (IOBENGUANE I-123) INJECTION [MEDI-PH...  ADREVIEW  \n",
       "2  AFINITOR (EVEROLIMUS) TABLET AFINITOR DISPERZ ...  AFINITOR  \n",
       "3  AMPYRA (DALFAMPRIDINE) TABLET, FILM COATED, EX...    AMPYRA  \n",
       "4  AMYVID (FLORBETAPIR F 18) INJECTION, SOLUTION ...    AMYVID  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33efd925-668d-43b9-aba5-d820f6a80c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_directory = '../../onsides-v4/data/train_xml/'\n",
    "\n",
    "# Clear the destination directory first\n",
    "if os.path.exists(destination_directory):\n",
    "    # Remove the entire directory and its contents\n",
    "    shutil.rmtree(destination_directory)\n",
    "\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# Now proceed to copy or move files\n",
    "for num in range(5):\n",
    "    directory = f'../../onsides-v4/data/spl/rx/dm_spl_release_human_rx_part{num + 1}/prescription'\n",
    "    \n",
    "    for file in train_select:\n",
    "        # Ensure 'file' is a string and not something else\n",
    "        if not isinstance(file, (str, bytes, os.PathLike)):\n",
    "            print(f\"Skipping invalid file: {file}\")\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(directory, file)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            # print(f\"File does not exist: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Open and read the JSON file\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                setid = data['set_id']  # Extract SETID from the file\n",
    "        \n",
    "            # Lookup xml_title in train_df\n",
    "            xml_title = train_df[train_df['SETID'] == setid]['xml_title'].iloc[0] if not train_df[train_df['SETID'] == setid].empty else 'unknown'\n",
    "        \n",
    "            # Construct new filename\n",
    "            new_filename = f\"{xml_title}_{setid}.json\"  # Assuming you want to save it as .json\n",
    "        \n",
    "            # Copy the file with the new name\n",
    "            shutil.copy(file_path, os.path.join(destination_directory, new_filename))\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89ab4595-0836-43e1-84d6-3c34d238e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_directory = '../../onsides-v4/data/gold_xml/'\n",
    "\n",
    "# Clear the destination directory first\n",
    "if os.path.exists(destination_directory):\n",
    "    # Remove the entire directory and its contents\n",
    "    shutil.rmtree(destination_directory)\n",
    "\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# Now proceed to copy or move files\n",
    "for num in range(5):\n",
    "    directory = f'../../onsides-v4/data/spl/rx/dm_spl_release_human_rx_part{num + 1}/prescription'\n",
    "    \n",
    "    for file in gold_select:\n",
    "        # Ensure 'file' is a string and not something else\n",
    "        if not isinstance(file, (str, bytes, os.PathLike)):\n",
    "            print(f\"Skipping invalid file: {file}\")\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(directory, file)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            # print(f\"File does not exist: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Open and read the JSON file\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                setid = data['set_id']  # Extract SETID from the file\n",
    "\n",
    "            # Lookup xml_title in train_df\n",
    "            xml_title = gold_df[gold_df['SETID'] == setid]['xml_title'].iloc[0] if not gold_df[gold_df['SETID'] == setid].empty else 'unknown'\n",
    "\n",
    "            # Construct new filename\n",
    "            new_filename = f\"{xml_title}_{setid}.json\"  # Assuming you want to save it as .json\n",
    "\n",
    "            # Copy or move the file with the new name\n",
    "            shutil.copy(file_path, os.path.join(destination_directory, new_filename))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
