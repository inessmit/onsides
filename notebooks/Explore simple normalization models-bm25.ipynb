{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tqdm\n",
    "from itertools import permutations\n",
    "\n",
    "# from fuzzyset import FuzzySet\n",
    "\n",
    "# from cfuzzyset import cFuzzySet as FuzzySet\n",
    "\n",
    "from rank_bm25 import BM25Okapi, BM25L, BM25Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the strings from meddra 23.1 and map them to the preferred term id\n",
    "fh = open('../data/meddra_pt_llt_map_omop_v23.1.csv')\n",
    "reader = csv.reader(fh)\n",
    "header = next(reader)\n",
    "\n",
    "meddra_strings = dict()\n",
    "\n",
    "for pt_concept_id, pt_concept_name, pt_meddra_id, llt_concept_id, llt_concept_name, llt_meddra_id in reader:\n",
    "    \n",
    "    meddra_strings[pt_concept_name.lower()] =  pt_meddra_id\n",
    "    meddra_strings[llt_concept_name.lower()] = pt_meddra_id\n",
    "        \n",
    "\n",
    "fh.close()\n",
    "meddra_strings_sorted = sorted(meddra_strings.keys())\n",
    "meddra_ids_23_1 = set(meddra_strings.values())\n",
    "\n",
    "tokenized_corpus = [term.split() for term in meddra_strings_sorted]\n",
    "bm25 = BM25Okapi(tokenized_corpus, k1=1.2, b=0.75, epsilon=1.0)\n",
    "# bm25 = BM25L(tokenized_corpus, k1=1.2, b=0.75, delta=0.5)\n",
    "# bm25 = BM25Plus(tokenized_corpus, k1=1.2, b=0.75, delta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from the provided XML documents and parsed\n",
    "# by the ../src/normalization_construct_trainingdata_step2_buildmap.py script.\n",
    "\n",
    "fh = open('../data/normalization/train_xml_normalization_map_step2.txt')\n",
    "reader = csv.reader(fh)\n",
    "header = next(reader)\n",
    "\n",
    "training_map = dict()\n",
    "\n",
    "for source_xml, string, meddra_pt_id, is_abbreviation, expanded_term in reader:\n",
    "    \n",
    "    if not meddra_pt_id in meddra_ids_23_1:\n",
    "        continue\n",
    "    \n",
    "    query_string = string.lower()\n",
    "    \n",
    "    if is_abbreviation == 'True':\n",
    "        query_string = expanded_term.lower()\n",
    "    \n",
    "    training_map[query_string] = meddra_pt_id\n",
    "    \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1336, 13858, 0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the expected meddra ids are in our reference set of meddra strings\n",
    "\n",
    "meddra_ids_map = set(training_map.values())\n",
    "len(meddra_ids_map), len(meddra_ids_23_1), len(meddra_ids_map-meddra_ids_23_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1392, 2648)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_to_match = set()\n",
    "for term in training_map.keys():\n",
    "    if term in meddra_strings:\n",
    "        # exact match, skip\n",
    "        continue\n",
    "    \n",
    "    terms_to_match.add(term)\n",
    "\n",
    "len(terms_to_match), len(training_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_matches = len(training_map)-len(terms_to_match)\n",
    "exact_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elevations in fasting serum ldl 10024910\n",
      "10024900 ldl\n",
      "10020635 fasting hyperglycaemia\n",
      "10020635 fasting hyperglycemia\n",
      "10020993 fasting hypoglycaemia\n",
      "10020993 fasting hypoglycemia\n",
      "10005342 arsenic in serum\n",
      "10024910 increased ldl\n",
      "10024909 low ldl\n",
      "10051718 ldl apheresis\n",
      "10024900 ldl cholesterol\n"
     ]
    }
   ],
   "source": [
    "query = list(terms_to_match)[6]\n",
    "tokenized_query = query.split()\n",
    "doc_scores = bm25.get_top_n(tokenized_query, meddra_strings_sorted, n=10)\n",
    "print(query, training_map[query])\n",
    "for term in doc_scores:\n",
    "    print(meddra_strings[term], term)\n",
    "# doc_scores, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1392/1392 [00:56<00:00, 24.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3275862068965517, 0.6465256797583081)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for a in tqdm.tqdm(terms_to_match):\n",
    "    \n",
    "    tokenized_query = a.split()\n",
    "    top_term = bm25.get_top_n(tokenized_query, meddra_strings_sorted, n=1)[0]\n",
    "    pred_meddra_pt_id = meddra_strings[top_term]\n",
    "\n",
    "    if pred_meddra_pt_id == training_map[a]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "correct/(incorrect+correct), (correct+exact_matches)/(incorrect+correct+exact_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1392/1392 [00:58<00:00, 23.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6494252873563219, 0.8157099697885196)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is the correct mapping within the top N?\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for a in tqdm.tqdm(terms_to_match):\n",
    "    \n",
    "    tokenized_query = a.split()\n",
    "    top_terms = bm25.get_top_n(tokenized_query, meddra_strings_sorted, n=10)\n",
    "    pred_meddra_pt_ids = [meddra_strings[t] for t in top_terms]\n",
    "\n",
    "    if training_map[a] in pred_meddra_pt_ids:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "correct/(incorrect+correct), (correct+exact_matches)/(incorrect+correct+exact_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1392/1392 [00:58<00:00, 23.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.504424778761062, 0.7925925925925926)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the performance of the top prediction if we \n",
    "# only look at those where the right answer is in the top 10?\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for a in tqdm.tqdm(terms_to_match):\n",
    "    \n",
    "    tokenized_query = a.split()\n",
    "    top_terms = bm25.get_top_n(tokenized_query, meddra_strings_sorted, n=10)\n",
    "    pred_meddra_pt_ids = [meddra_strings[t] for t in top_terms]\n",
    "    if not training_map[a] in pred_meddra_pt_ids:\n",
    "        continue\n",
    "    \n",
    "    pred_meddra_pt_id = meddra_strings[top_terms[0]]\n",
    "\n",
    "    if pred_meddra_pt_id == training_map[a]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "correct/(incorrect+correct), (correct+exact_matches)/(incorrect+correct+exact_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
