{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fcd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tqdm\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from cfuzzyset import cFuzzySet as FuzzySet\n",
    "from rank_bm25 import BM25Okapi, BM25L, BM25Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc63953f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 diabet type'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text, sort=True):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    stems =  stem_tokens(tokens, stemmer)\n",
    "    if sort:\n",
    "        stems = sorted(stems)\n",
    "    \n",
    "    return ' '.join(stems)\n",
    "\n",
    "tokenize(\"type 2 diabetes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31be9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from the provided XML documents and parsed\n",
    "# by the ../src/normalization_construct_trainingdata_step2_buildmap.py script.\n",
    "\n",
    "fh = open('../data/normalization/train_xml_normalization_map_step2.txt')\n",
    "reader = csv.reader(fh)\n",
    "header = next(reader)\n",
    "\n",
    "training_map = dict()\n",
    "\n",
    "for source_xml, raw_string, meddra_pt_id, is_abbreviation, expanded_term in reader:\n",
    "    \n",
    "    query_string = raw_string.lower()\n",
    "    \n",
    "    if is_abbreviation == 'True':\n",
    "        query_string = expanded_term.lower()\n",
    "    \n",
    "    training_map[tokenize(query_string)] = meddra_pt_id\n",
    "    \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fed854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58590"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all the strings from meddra 23.1 and map them to the preferred term id\n",
    "fh = open('../data/meddra_pt_llt_map_omop_v23.1.csv')\n",
    "reader = csv.reader(fh)\n",
    "header = next(reader)\n",
    "\n",
    "meddra_strings = dict()\n",
    "meddra_fuzzyset = FuzzySet()\n",
    "\n",
    "for pt_concept_id, pt_concept_name, pt_meddra_id, llt_concept_id, llt_concept_name, llt_meddra_id in reader:\n",
    "    \n",
    "    meddra_strings[tokenize(pt_concept_name.lower())] =  pt_meddra_id\n",
    "    meddra_strings[tokenize(llt_concept_name.lower())] = pt_meddra_id\n",
    "    \n",
    "    meddra_fuzzyset.add(tokenize(pt_concept_name.lower()))\n",
    "    meddra_fuzzyset.add(tokenize(llt_concept_name.lower()))\n",
    "    \n",
    "\n",
    "fh.close()\n",
    "\n",
    "# BM25 setup\n",
    "meddra_strings_sorted = sorted(meddra_strings.keys())\n",
    "tokenized_corpus = [term.split() for term in meddra_strings_sorted]\n",
    "bm25 = BM25Okapi(tokenized_corpus, k1=1.2, b=0.75, epsilon=1.0)\n",
    "\n",
    "len(meddra_strings)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e0525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
